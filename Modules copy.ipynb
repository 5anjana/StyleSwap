{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Losses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### accuracy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, target, topk=1, thresh=None):\n",
    "    \"\"\"Calculate accuracy according to the prediction and target.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): The model prediction, shape (N, num_class, ...)\n",
    "        target (torch.Tensor): The target of each prediction, shape (N, , ...)\n",
    "        topk (int | tuple[int], optional): If the predictions in ``topk``\n",
    "            matches the target, the predictions will be regarded as\n",
    "            correct ones. Defaults to 1.\n",
    "        thresh (float, optional): If not None, predictions with scores under\n",
    "            this threshold are considered incorrect. Default to None.\n",
    "\n",
    "    Returns:\n",
    "        float | tuple[float]: If the input ``topk`` is a single integer,\n",
    "            the function will return a single float as accuracy. If\n",
    "            ``topk`` is a tuple containing multiple integers, the\n",
    "            function will return a tuple containing accuracies of\n",
    "            each ``topk`` number.\n",
    "    \"\"\"\n",
    "    assert isinstance(topk, (int, tuple)) # topk should be int or tuple \n",
    "    if isinstance(topk, int):\n",
    "        topk = (topk, )\n",
    "        return_single = True\n",
    "    else:\n",
    "        return_single = False # convert topk to tuple if int, track how many values user passed\n",
    "\n",
    "    maxk = max(topk) # max number of top predictions we'll evaluate\n",
    "    if pred.size(0) == 0:\n",
    "        accu = [pred.new_tensor(0.) for i in range(len(topk))]\n",
    "        return accu[0] if return_single else accu # check if pred batch is empty\n",
    "    assert pred.ndim == target.ndim + 1 # checks that pred has one more dimension than target\n",
    "    assert pred.size(0) == target.size(0) # same size\n",
    "    assert maxk <= pred.size(1), \\\n",
    "        f'maxk {maxk} exceeds pred dimension {pred.size(1)}'\n",
    "    pred_value, pred_label = pred.topk(maxk, dim=1) # selects topk predictions and their indices\n",
    "    # transpose to shape (maxk, N, ...)\n",
    "    pred_label = pred_label.transpose(0, 1)\n",
    "    correct = pred_label.eq(target.unsqueeze(0).expand_as(pred_label)) # makes correct a boolean matrix (whether top-k predictions match the target)\n",
    "    if thresh is not None:\n",
    "        # Only prediction values larger than thresh are counted as correct\n",
    "        correct = correct & (pred_value > thresh).t() # masks out prediction below threshold with top-k scores\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / target.numel()))\n",
    "    return res[0] if return_single else res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_loss(loss, reduction):\n",
    "    \"\"\"Reduce loss as specified.\n",
    "\n",
    "    Args:\n",
    "        loss (Tensor): Elementwise loss tensor.\n",
    "        reduction (str): Options are \"none\", \"mean\" and \"sum\".\n",
    "\n",
    "    Return:\n",
    "        Tensor: Reduced loss tensor.\n",
    "    \"\"\"\n",
    "    reduction_enum = F._Reduction.get_enum(reduction)\n",
    "    # none: 0, elementwise_mean:1, sum: 2\n",
    "    if reduction_enum == 0:\n",
    "        return loss\n",
    "    elif reduction_enum == 1:\n",
    "        return loss.mean()\n",
    "    elif reduction_enum == 2:\n",
    "        return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_reduce_loss(loss, weight=None, reduction='mean', avg_factor=None):\n",
    "    \"\"\"Apply element-wise weight and reduce loss.\n",
    "\n",
    "    Args:\n",
    "        loss (Tensor): Element-wise loss.\n",
    "        weight (Tensor): Element-wise weights.\n",
    "        reduction (str): Same as built-in losses of PyTorch.\n",
    "        avg_factor (float): Avarage factor when computing the mean of losses.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Processed loss values.\n",
    "    \"\"\"\n",
    "    # if weight is specified, apply element-wise weight\n",
    "    if weight is not None:\n",
    "        assert weight.dim() == loss.dim()\n",
    "        if weight.dim() > 1:\n",
    "            assert weight.size(1) == 1 or weight.size(1) == loss.size(1)\n",
    "        loss = loss * weight\n",
    "\n",
    "    # if avg_factor is not specified, just reduce the loss\n",
    "    if avg_factor is None:\n",
    "        loss = reduce_loss(loss, reduction)\n",
    "    else:\n",
    "        # if reduction is mean, then average the loss by avg_factor\n",
    "        if reduction == 'mean':\n",
    "            loss = loss.sum() / avg_factor\n",
    "        # if reduction is 'none', then do nothing, otherwise raise an error\n",
    "        elif reduction != 'none':\n",
    "            raise ValueError('avg_factor can not be used with reduction=\"sum\"')\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(pred,\n",
    "                  label,\n",
    "                  weight=None,\n",
    "                  class_weight=None,\n",
    "                  reduction='mean',\n",
    "                  avg_factor=None,\n",
    "                  ignore_index=-100):\n",
    "    \"\"\"The wrapper function for :func:`F.cross_entropy`\"\"\"\n",
    "    # class_weight is a manual rescaling weight given to each class.\n",
    "    # If given, has to be a Tensor of size C element-wise losses\n",
    "    loss = F.cross_entropy(\n",
    "        pred,\n",
    "        label,\n",
    "        weight=class_weight,\n",
    "        reduction='none',\n",
    "        ignore_index=ignore_index)\n",
    "\n",
    "    # apply weights and do the reduction\n",
    "    if weight is not None:\n",
    "        weight = weight.float()\n",
    "    loss = weight_reduce_loss(\n",
    "        loss, weight=weight, reduction=reduction, avg_factor=avg_factor)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _expand_onehot_labels(labels, label_weights, target_shape, ignore_index):\n",
    "    \"\"\"Expand onehot labels to match the size of prediction.\"\"\"\n",
    "    bin_labels = labels.new_zeros(target_shape)\n",
    "    valid_mask = (labels >= 0) & (labels != ignore_index)\n",
    "    inds = torch.nonzero(valid_mask, as_tuple=True)\n",
    "\n",
    "    if inds[0].numel() > 0:\n",
    "        if labels.dim() == 3:\n",
    "            bin_labels[inds[0], labels[valid_mask], inds[1], inds[2]] = 1\n",
    "        else:\n",
    "            bin_labels[inds[0], labels[valid_mask]] = 1\n",
    "\n",
    "    valid_mask = valid_mask.unsqueeze(1).expand(target_shape).float()\n",
    "    if label_weights is None:\n",
    "        bin_label_weights = valid_mask\n",
    "    else:\n",
    "        bin_label_weights = label_weights.unsqueeze(1).expand(target_shape)\n",
    "        bin_label_weights *= valid_mask\n",
    "\n",
    "    return bin_labels, bin_label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(pred,\n",
    "                         label,\n",
    "                         weight=None,\n",
    "                         reduction='mean',\n",
    "                         avg_factor=None,\n",
    "                         class_weight=None,\n",
    "                         ignore_index=255):\n",
    "    \"\"\"Calculate the binary CrossEntropy loss.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): The prediction with shape (N, 1).\n",
    "        label (torch.Tensor): The learning label of the prediction.\n",
    "        weight (torch.Tensor, optional): Sample-wise loss weight.\n",
    "        reduction (str, optional): The method used to reduce the loss.\n",
    "            Options are \"none\", \"mean\" and \"sum\".\n",
    "        avg_factor (int, optional): Average factor that is used to average\n",
    "            the loss. Defaults to None.\n",
    "        class_weight (list[float], optional): The weight for each class.\n",
    "        ignore_index (int | None): The label index to be ignored. Default: 255\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The calculated loss\n",
    "    \"\"\"\n",
    "    if pred.dim() != label.dim():\n",
    "        assert (pred.dim() == 2 and label.dim() == 1) or (\n",
    "                pred.dim() == 4 and label.dim() == 3), \\\n",
    "            'Only pred shape [N, C], label shape [N] or pred shape [N, C, ' \\\n",
    "            'H, W], label shape [N, H, W] are supported'\n",
    "        label, weight = _expand_onehot_labels(label, weight, pred.shape,\n",
    "                                              ignore_index)\n",
    "\n",
    "    # weighted element-wise losses\n",
    "    if weight is not None:\n",
    "        weight = weight.float()\n",
    "    loss = F.binary_cross_entropy_with_logits(\n",
    "        pred, label.float(), pos_weight=class_weight, reduction='none')\n",
    "    # do the reduction for the weighted loss\n",
    "    loss = weight_reduce_loss(\n",
    "        loss, weight, reduction=reduction, avg_factor=avg_factor)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_cross_entropy(pred,\n",
    "                       target,\n",
    "                       label,\n",
    "                       reduction='mean',\n",
    "                       avg_factor=None,\n",
    "                       class_weight=None,\n",
    "                       ignore_index=None):\n",
    "    \"\"\"Calculate the CrossEntropy loss for masks.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): The prediction with shape (N, C), C is the number\n",
    "            of classes.\n",
    "        target (torch.Tensor): The learning label of the prediction.\n",
    "        label (torch.Tensor): ``label`` indicates the class label of the mask'\n",
    "            corresponding object. This will be used to select the mask in the\n",
    "            of the class which the object belongs to when the mask prediction\n",
    "            if not class-agnostic.\n",
    "        reduction (str, optional): The method used to reduce the loss.\n",
    "            Options are \"none\", \"mean\" and \"sum\".\n",
    "        avg_factor (int, optional): Average factor that is used to average\n",
    "            the loss. Defaults to None.\n",
    "        class_weight (list[float], optional): The weight for each class.\n",
    "        ignore_index (None): Placeholder, to be consistent with other loss.\n",
    "            Default: None.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The calculated loss\n",
    "    \"\"\"\n",
    "    assert ignore_index is None, 'BCE loss does not support ignore_index'\n",
    "    # TODO: handle these two reserved arguments\n",
    "    assert reduction == 'mean' and avg_factor is None\n",
    "    num_rois = pred.size()[0]\n",
    "    inds = torch.arange(0, num_rois, dtype=torch.long, device=pred.device)\n",
    "    pred_slice = pred[inds, label].squeeze(1)\n",
    "    return F.binary_cross_entropy_with_logits(\n",
    "        pred_slice, target, weight=class_weight, reduction='mean')[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy_loss(cls_score,\n",
    "                               label,\n",
    "                               *,\n",
    "                               use_sigmoid=False,\n",
    "                               use_mask=False,\n",
    "                               class_weight=None,\n",
    "                               loss_weight=1.0,\n",
    "                               weight=None,\n",
    "                               avg_factor=None,\n",
    "                               reduction='mean',\n",
    "                               reduction_override=None,\n",
    "                               ignore_index=-100,\n",
    "                               **kwargs):\n",
    "    \"\"\"\n",
    "    Functional equivalent of CrossEntropyLoss class forward method.\n",
    "\n",
    "    Args:\n",
    "        cls_score (Tensor): Prediction logits.\n",
    "        label (Tensor): Ground-truth labels.\n",
    "        use_sigmoid (bool): Use sigmoid + BCE.\n",
    "        use_mask (bool): Use mask cross-entropy.\n",
    "        class_weight (list[float] | Tensor | None): Per-class weight.\n",
    "        loss_weight (float): Scalar multiplier on the loss.\n",
    "        weight (Tensor | None): Sample-wise weighting.\n",
    "        avg_factor (float | None): Averaging factor for mean reduction.\n",
    "        reduction (str): 'none' | 'mean' | 'sum'.\n",
    "        reduction_override (str | None): Overrides the reduction method.\n",
    "        ignore_index (int): Label index to ignore.\n",
    "        kwargs: Passed to the specific loss function.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Computed loss.\n",
    "    \"\"\"\n",
    "    assert not (use_sigmoid and use_mask), \\\n",
    "        \"Cannot use both sigmoid and mask mode.\"\n",
    "\n",
    "    reduction = reduction_override if reduction_override else reduction\n",
    "\n",
    "    # Select the appropriate core loss function\n",
    "    if use_sigmoid:\n",
    "        loss_fn = binary_cross_entropy\n",
    "    elif use_mask:\n",
    "        loss_fn = mask_cross_entropy\n",
    "    else:\n",
    "        loss_fn = cross_entropy\n",
    "\n",
    "    # Convert class weights to tensor if needed\n",
    "    if class_weight is not None and not torch.is_tensor(class_weight):\n",
    "        class_weight = cls_score.new_tensor(class_weight)\n",
    "\n",
    "    return loss_weight * loss_fn(\n",
    "        cls_score,\n",
    "        label,\n",
    "        weight=weight,\n",
    "        class_weight=class_weight,\n",
    "        reduction=reduction,\n",
    "        avg_factor=avg_factor,\n",
    "        ignore_index=ignore_index,\n",
    "        **kwargs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Archs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fcn_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashle\\miniconda3\\envs\\Orientation_env\\Lib\\site-packages\\mmengine\\optim\\optimizer\\zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from mmcv.cnn import ConvModule #, normal_init\n",
    "#from mmseg.ops import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def init_decode_head(in_channels,\n",
    "                     channels,\n",
    "                     num_classes,\n",
    "                     dropout_ratio=0.1,\n",
    "                     conv_cfg=None,\n",
    "                     norm_cfg=dict(type='BN'),\n",
    "                     act_cfg=dict(type='ReLU'),\n",
    "                     in_index=-1,\n",
    "                     input_transform=None,\n",
    "                     ignore_index=255,\n",
    "                     align_corners=False):\n",
    "    \"\"\"\n",
    "    Initializes the decode head layers.\n",
    "\n",
    "    Returns:\n",
    "        dict containing initialized layers and parameters.\n",
    "    \"\"\"\n",
    "    in_channels = process_inputs(in_channels, in_index, input_transform)\n",
    "\n",
    "    conv_seg = nn.Conv2d(channels, num_classes, kernel_size=1)\n",
    "    dropout = nn.Dropout2d(dropout_ratio) if dropout_ratio > 0 else None\n",
    "\n",
    "    return {\n",
    "        'in_channels': in_channels,\n",
    "        'channels': channels,\n",
    "        'num_classes': num_classes,\n",
    "        'dropout_ratio': dropout_ratio,\n",
    "        'conv_cfg': conv_cfg,\n",
    "        'norm_cfg': norm_cfg,\n",
    "        'act_cfg': act_cfg,\n",
    "        'in_index': in_index,\n",
    "        'input_transform': input_transform,\n",
    "        'ignore_index': ignore_index,\n",
    "        'align_corners': align_corners,\n",
    "        'conv_seg': conv_seg,\n",
    "        'dropout': dropout\n",
    "    }\n",
    "\n",
    "def process_inputs(in_channels, in_index, input_transform):\n",
    "    \"\"\"\n",
    "    Processes input channel transformations.\n",
    "    \"\"\"\n",
    "    if input_transform is not None:\n",
    "        assert input_transform in ['resize_concat', 'multiple_select']\n",
    "        assert isinstance(in_channels, (list, tuple))\n",
    "        assert isinstance(in_index, (list, tuple))\n",
    "        assert len(in_channels) == len(in_index)\n",
    "        return sum(in_channels) if input_transform == 'resize_concat' else in_channels\n",
    "\n",
    "    assert isinstance(in_channels, int)\n",
    "    assert isinstance(in_index, int)\n",
    "    return in_channels\n",
    "\n",
    "def transform_inputs(inputs, config):\n",
    "    \"\"\"\n",
    "    Transforms inputs based on decode head settings.\n",
    "    \"\"\"\n",
    "    if config['input_transform'] == 'resize_concat':\n",
    "        inputs = [inputs[i] for i in config['in_index']]\n",
    "        upsampled_inputs = [\n",
    "            F.interpolate(\n",
    "                x,\n",
    "                size=inputs[0].shape[2:],\n",
    "                mode='bilinear',\n",
    "                align_corners=config['align_corners']) for x in inputs\n",
    "        ]\n",
    "        return torch.cat(upsampled_inputs, dim=1)\n",
    "\n",
    "    elif config['input_transform'] == 'multiple_select':\n",
    "        return [inputs[i] for i in config['in_index']]\n",
    "\n",
    "    return inputs[config['in_index']]\n",
    "\n",
    "def classify_pixels(feat, config):\n",
    "    \"\"\"\n",
    "    Applies dropout and convolutional classification layer.\n",
    "    \"\"\"\n",
    "    if config['dropout']:\n",
    "        feat = config['dropout'](feat)\n",
    "    return config['conv_seg'](feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_fcn_head(num_convs=2, kernel_size=3, concat_input=True, base_config=None):\n",
    "    \"\"\"\n",
    "    Initializes FCNHead parameters and layers.\n",
    "\n",
    "    Args:\n",
    "        num_convs (int): Number of convolutions in the head.\n",
    "        kernel_size (int): Kernel size for convolutions.\n",
    "        concat_input (bool): Whether to concatenate input with output before classification.\n",
    "        base_config (dict): Configuration from BaseDecodeHead.\n",
    "\n",
    "    Returns:\n",
    "        dict containing initialized layers and parameters.\n",
    "    \"\"\"\n",
    "    assert num_convs >= 0, \"Number of convolutions must be non-negative\"\n",
    "    \n",
    "    if num_convs == 0:\n",
    "        assert base_config['in_channels'] == base_config['channels'], \"in_channels must match channels when num_convs=0\"\n",
    "    \n",
    "    convs = build_convs(num_convs, kernel_size, base_config)\n",
    "    \n",
    "    conv_cat = None\n",
    "    if concat_input:\n",
    "        conv_cat = nn.Conv2d(\n",
    "            base_config['in_channels'] + base_config['channels'],\n",
    "            base_config['channels'],\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size // 2\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        'num_convs': num_convs,\n",
    "        'kernel_size': kernel_size,\n",
    "        'concat_input': concat_input,\n",
    "        'base_config': base_config,\n",
    "        'convs': convs,\n",
    "        'conv_cat': conv_cat\n",
    "    }\n",
    "\n",
    "def build_convs(num_convs, kernel_size, base_config):\n",
    "    \"\"\"\n",
    "    Builds a sequence of convolutional layers.\n",
    "    \"\"\"\n",
    "    if num_convs == 0:\n",
    "        return nn.Identity()\n",
    "\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(base_config['in_channels'], base_config['channels'], kernel_size, padding=kernel_size//2))\n",
    "    \n",
    "    for _ in range(num_convs - 1):\n",
    "        layers.append(nn.Conv2d(base_config['channels'], base_config['channels'], kernel_size, padding=kernel_size//2))\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def fcn_head_forward(inputs, config):\n",
    "    \"\"\"\n",
    "    Forward pass for FCNHead.\n",
    "\n",
    "    Args:\n",
    "        inputs (torch.Tensor): Input tensor.\n",
    "        config (dict): Configuration dictionary.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Output segmentation logits.\n",
    "    \"\"\"\n",
    "    x = transform_inputs(inputs, config['base_config'])\n",
    "    output = config['convs'](x)\n",
    "\n",
    "    if config['concat_input']:\n",
    "        output = torch.cat([x, output], dim=1)\n",
    "        output = config['conv_cat'](output)\n",
    "\n",
    "    output = classify_pixels(output, config['base_config'])\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def init_multihead_fcn(in_channels, channels, num_classes, num_convs=2, kernel_size=3, \n",
    "                       concat_input=True, num_heads=18, dropout_ratio=0.1, base_config=None):\n",
    "    \"\"\"\n",
    "    Initializes MultiHeadFCN parameters and layers.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Input channels.\n",
    "        channels (int): Internal feature channels.\n",
    "        num_classes (int): Number of segmentation classes.\n",
    "        num_convs (int): Number of convolutions per head.\n",
    "        kernel_size (int): Convolution kernel size.\n",
    "        concat_input (bool): Whether to concatenate input with output.\n",
    "        num_heads (int): Number of segmentation heads.\n",
    "        dropout_ratio (float): Dropout probability.\n",
    "        base_config (dict): Configuration from BaseDecodeHead.\n",
    "\n",
    "    Returns:\n",
    "        dict containing initialized layers and parameters.\n",
    "    \"\"\"\n",
    "    assert num_convs >= 0, \"Number of convolutions must be non-negative\"\n",
    "    \n",
    "    dropout = nn.Dropout2d(dropout_ratio) if dropout_ratio > 0 else None\n",
    "\n",
    "    conv_heads = build_multihead_classifiers(num_heads, channels, num_classes)\n",
    "    convs, conv_cats = build_multihead_convs(num_heads, num_convs, kernel_size, in_channels, channels, concat_input)\n",
    "\n",
    "    return {\n",
    "        'in_channels': in_channels,\n",
    "        'channels': channels,\n",
    "        'num_classes': num_classes,\n",
    "        'num_convs': num_convs,\n",
    "        'kernel_size': kernel_size,\n",
    "        'concat_input': concat_input,\n",
    "        'num_heads': num_heads,\n",
    "        'dropout': dropout,\n",
    "        'conv_heads': conv_heads,\n",
    "        'convs': convs,\n",
    "        'conv_cats': conv_cats,\n",
    "        'base_config': base_config\n",
    "    }\n",
    "\n",
    "def build_multihead_classifiers(num_heads, channels, num_classes):\n",
    "    \"\"\"Creates multiple classification heads.\"\"\"\n",
    "    return nn.ModuleList([nn.Conv2d(channels, num_classes, kernel_size=1) for _ in range(num_heads)])\n",
    "\n",
    "def build_multihead_convs(num_heads, num_convs, kernel_size, in_channels, channels, concat_input):\n",
    "    \"\"\"Builds multiple convolutional branches.\"\"\"\n",
    "    convs_list = []\n",
    "    conv_cat_list = []\n",
    "\n",
    "    for _ in range(num_heads):\n",
    "        convs = []\n",
    "        convs.append(nn.Conv2d(in_channels, channels, kernel_size, padding=kernel_size//2))\n",
    "        \n",
    "        for _ in range(num_convs - 1):\n",
    "            convs.append(nn.Conv2d(channels, channels, kernel_size, padding=kernel_size//2))\n",
    "\n",
    "        convs_list.append(nn.Sequential(*convs) if num_convs > 0 else nn.Identity())\n",
    "\n",
    "        if concat_input:\n",
    "            conv_cat_list.append(nn.Conv2d(in_channels + channels, channels, kernel_size, padding=kernel_size//2))\n",
    "\n",
    "    return nn.ModuleList(convs_list), nn.ModuleList(conv_cat_list)\n",
    "\n",
    "def multihead_fcn_forward(inputs, config):\n",
    "    \"\"\"\n",
    "    Forward pass for MultiHeadFCN.\n",
    "\n",
    "    Args:\n",
    "        inputs (torch.Tensor): Input tensor.\n",
    "        config (dict): Configuration dictionary.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: Output segmentation logits for each head.\n",
    "    \"\"\"\n",
    "    x = transform_inputs(inputs, config['base_config'])\n",
    "    output_list = []\n",
    "\n",
    "    for head_idx in range(config['num_heads']):\n",
    "        output = config['convs'][head_idx](x)\n",
    "\n",
    "        if config['concat_input']:\n",
    "            output = config['conv_cats'][head_idx](torch.cat([x, output], dim=1))\n",
    "\n",
    "        if config['dropout']:\n",
    "            output = config['dropout'](output)\n",
    "\n",
    "        output = config['conv_heads'][head_idx](output)\n",
    "        output_list.append(output)\n",
    "\n",
    "    return output_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### unet arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.checkpoint as cp\n",
    "from mmcv.cnn import (ConvModule, build_activation_layer,\n",
    "                      build_norm_layer, build_upsample_layer)\n",
    "#from mmcv.runner import load_checkpoint\n",
    "#from mmseg.utils import get_root_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mmcv.cnn import ConvModule, build_upsample_layer\n",
    "\n",
    "def build_upconv_block(\n",
    "    conv_block,\n",
    "    in_channels,\n",
    "    skip_channels,\n",
    "    out_channels,\n",
    "    num_convs=2,\n",
    "    stride=1,\n",
    "    dilation=1,\n",
    "    with_cp=False,\n",
    "    conv_cfg=None,\n",
    "    norm_cfg=dict(type='BN'),\n",
    "    act_cfg=dict(type='ReLU'),\n",
    "    upsample_cfg=dict(type='InterpConv'),\n",
    "    dcn=None,\n",
    "    plugins=None\n",
    "):\n",
    "    \"\"\"Builds the upsample and conv blocks used in UNet decoder.\"\"\"\n",
    "\n",
    "    assert dcn is None, 'Not implemented yet.'\n",
    "    assert plugins is None, 'Not implemented yet.'\n",
    "\n",
    "    conv_block_inst = conv_block(\n",
    "        in_channels=2 * skip_channels,\n",
    "        out_channels=out_channels,\n",
    "        num_convs=num_convs,\n",
    "        stride=stride,\n",
    "        dilation=dilation,\n",
    "        with_cp=with_cp,\n",
    "        conv_cfg=conv_cfg,\n",
    "        norm_cfg=norm_cfg,\n",
    "        act_cfg=act_cfg,\n",
    "        dcn=None,\n",
    "        plugins=None\n",
    "    )\n",
    "\n",
    "    if upsample_cfg is not None:\n",
    "        upsample_inst = build_upsample_layer(\n",
    "            cfg=upsample_cfg,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=skip_channels,\n",
    "            with_cp=with_cp,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg\n",
    "        )\n",
    "    else:\n",
    "        upsample_inst = ConvModule(\n",
    "            in_channels,\n",
    "            skip_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            conv_cfg=conv_cfg,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg\n",
    "        )\n",
    "\n",
    "    return conv_block_inst, upsample_inst\n",
    "\n",
    "def upconv_block_forward(skip, x, conv_block, upsample):\n",
    "    \"\"\"Forward function for upsample + conv block.\"\"\"\n",
    "    x = upsample(x)\n",
    "    out = torch.cat([skip, x], dim=1)\n",
    "    out = conv_block(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as cp\n",
    "from mmcv.cnn import ConvModule\n",
    "\n",
    "def build_basic_conv_block(\n",
    "    in_channels,\n",
    "    out_channels,\n",
    "    num_convs=2,\n",
    "    stride=1,\n",
    "    dilation=1,\n",
    "    with_cp=False,\n",
    "    conv_cfg=None,\n",
    "    norm_cfg=dict(type='BN'),\n",
    "    act_cfg=dict(type='ReLU'),\n",
    "    dcn=None,\n",
    "    plugins=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds a basic convolutional block for UNet.\n",
    "\n",
    "    This block consists of several plain convolutional layers (Conv + Norm + Activation).\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        num_convs (int): Number of convolutional layers. Default: 2.\n",
    "        stride (int): If stride=2, applies stride convolution in the first layer. Default: 1.\n",
    "        dilation (int): Dilation rate for all conv layers except the first. Default: 1.\n",
    "        with_cp (bool): If True, enables checkpointing for memory savings. Default: False.\n",
    "        conv_cfg (dict | None): Configuration for convolution layer. Default: None.\n",
    "        norm_cfg (dict | None): Configuration for normalization layer. Default: dict(type='BN').\n",
    "        act_cfg (dict | None): Configuration for activation function. Default: dict(type='ReLU').\n",
    "        dcn (bool): Deformable convolution support. Not implemented. Default: None.\n",
    "        plugins (dict): Plugins for conv layers. Not implemented. Default: None.\n",
    "\n",
    "    Returns:\n",
    "        nn.Sequential: A sequential module containing the convolutional layers.\n",
    "        bool: Whether checkpointing is enabled.\n",
    "    \"\"\"\n",
    "    assert dcn is None, 'Not implemented yet.'\n",
    "    assert plugins is None, 'Not implemented yet.'\n",
    "\n",
    "    convs = []\n",
    "    for i in range(num_convs):\n",
    "        convs.append(\n",
    "            ConvModule(\n",
    "                in_channels=in_channels if i == 0 else out_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=stride if i == 0 else 1,\n",
    "                dilation=1 if i == 0 else dilation,\n",
    "                padding=1 if i == 0 else dilation,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=act_cfg\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return nn.Sequential(*convs), with_cp\n",
    "\n",
    "\n",
    "def basic_conv_block_forward(x, convs, with_cp):\n",
    "    \"\"\"\n",
    "    Forward function for basic convolutional block.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Input tensor.\n",
    "        convs (nn.Sequential): Convolutional layers.\n",
    "        with_cp (bool): Whether checkpointing is enabled.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Output tensor after applying convs.\n",
    "    \"\"\"\n",
    "    if with_cp and x.requires_grad:\n",
    "        return cp.checkpoint(convs, x)\n",
    "    else:\n",
    "        return convs(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as cp\n",
    "from mmcv.cnn import build_norm_layer, build_activation_layer\n",
    "\n",
    "def build_deconv_module(\n",
    "    in_channels,\n",
    "    out_channels,\n",
    "    with_cp=False,\n",
    "    norm_cfg=dict(type='BN'),\n",
    "    act_cfg=dict(type='ReLU'),\n",
    "    *,\n",
    "    kernel_size=4,\n",
    "    scale_factor=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds a deconvolution upsample module for UNet decoder (2x upsample).\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        with_cp (bool): Whether to use checkpointing. Default: False.\n",
    "        norm_cfg (dict | None): Config dict for normalization layer. Default: dict(type='BN').\n",
    "        act_cfg (dict | None): Config dict for activation function. Default: dict(type='ReLU').\n",
    "        kernel_size (int): Kernel size of the transposed convolution. Default: 4.\n",
    "        scale_factor (int): Upsampling factor (stride). Default: 2.\n",
    "\n",
    "    Returns:\n",
    "        nn.Sequential: A sequential module for deconv -> norm -> activation.\n",
    "        bool: Whether checkpointing is enabled.\n",
    "    \"\"\"\n",
    "    assert (kernel_size - scale_factor >= 0) and \\\n",
    "           (kernel_size - scale_factor) % 2 == 0, (\n",
    "        f'Invalid kernel/scale config: kernel_size={kernel_size}, scale_factor={scale_factor}. '\n",
    "        'kernel_size must be >= scale_factor and their difference must be even.')\n",
    "\n",
    "    stride = scale_factor\n",
    "    padding = (kernel_size - scale_factor) // 2\n",
    "\n",
    "    deconv = nn.ConvTranspose2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        stride=stride,\n",
    "        padding=padding\n",
    "    )\n",
    "\n",
    "    _, norm = build_norm_layer(norm_cfg, out_channels)\n",
    "    activate = build_activation_layer(act_cfg)\n",
    "\n",
    "    module = nn.Sequential(deconv, norm, activate)\n",
    "    return module, with_cp\n",
    "\n",
    "\n",
    "def deconv_module_forward(x, module, with_cp):\n",
    "    \"\"\"\n",
    "    Forward function for the deconvolution upsampling module.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Input tensor.\n",
    "        module (nn.Sequential): Deconv -> Norm -> Activation module.\n",
    "        with_cp (bool): Whether checkpointing is enabled.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Output tensor.\n",
    "    \"\"\"\n",
    "    if with_cp and x.requires_grad:\n",
    "        return cp.checkpoint(module, x)\n",
    "    else:\n",
    "        return module(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as cp\n",
    "from mmcv.cnn import ConvModule\n",
    "\n",
    "def build_interp_conv(\n",
    "    in_channels,\n",
    "    out_channels,\n",
    "    with_cp=False,\n",
    "    norm_cfg=dict(type='BN'),\n",
    "    act_cfg=dict(type='ReLU'),\n",
    "    *,\n",
    "    conv_cfg=None,\n",
    "    conv_first=False,\n",
    "    kernel_size=1,\n",
    "    stride=1,\n",
    "    padding=0,\n",
    "    upsample_cfg=dict(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds an interpolation-based upsample module for the UNet decoder.\n",
    "\n",
    "    This module performs interpolation upsampling followed by a convolutional\n",
    "    block, or vice versa depending on `conv_first`.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        with_cp (bool): Use checkpointing to reduce memory. Default: False.\n",
    "        norm_cfg (dict): Normalization layer config. Default: dict(type='BN').\n",
    "        act_cfg (dict): Activation layer config. Default: dict(type='ReLU').\n",
    "        conv_cfg (dict | None): Convolution config. Default: None.\n",
    "        conv_first (bool): Whether to apply convolution before upsampling. Default: False.\n",
    "        kernel_size (int): Kernel size of the convolution. Default: 1.\n",
    "        stride (int): Stride of the convolution. Default: 1.\n",
    "        padding (int): Padding for the convolution. Default: 0.\n",
    "        upsample_cfg (dict): Config for `nn.Upsample`. Default: bilinear 2x.\n",
    "\n",
    "    Returns:\n",
    "        nn.Sequential: A sequential module (Upsample + Conv or Conv + Upsample).\n",
    "        bool: Whether checkpointing is enabled.\n",
    "    \"\"\"\n",
    "    conv = ConvModule(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        conv_cfg=conv_cfg,\n",
    "        norm_cfg=norm_cfg,\n",
    "        act_cfg=act_cfg\n",
    "    )\n",
    "\n",
    "    upsample = nn.Upsample(**upsample_cfg)\n",
    "\n",
    "    if conv_first:\n",
    "        module = nn.Sequential(conv, upsample)\n",
    "    else:\n",
    "        module = nn.Sequential(upsample, conv)\n",
    "\n",
    "    return module, with_cp\n",
    "\n",
    "\n",
    "def interp_conv_forward(x, module, with_cp):\n",
    "    \"\"\"\n",
    "    Forward function for the interpolation-based upsampling module.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Input tensor.\n",
    "        module (nn.Sequential): Upsample + Conv or Conv + Upsample.\n",
    "        with_cp (bool): Whether checkpointing is enabled.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Output tensor after upsampling and convolution.\n",
    "    \"\"\"\n",
    "    if with_cp and x.requires_grad:\n",
    "        return cp.checkpoint(module, x)\n",
    "    else:\n",
    "        return module(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(in_channels=3,\n",
    "               base_channels=64,\n",
    "               num_stages=5,\n",
    "               strides=(1, 1, 1, 1, 1),\n",
    "               enc_num_convs=(2, 2, 2, 2, 2),\n",
    "               dec_num_convs=(2, 2, 2, 2),\n",
    "               downsamples=(True, True, True, True),\n",
    "               enc_dilations=(1, 1, 1, 1, 1),\n",
    "               dec_dilations=(1, 1, 1, 1),\n",
    "               with_cp=False,\n",
    "               conv_cfg=None,\n",
    "               norm_cfg=dict(type='BN'),\n",
    "               act_cfg=dict(type='ReLU'),\n",
    "               upsample_cfg=dict(type='InterpConv'),\n",
    "               norm_eval=False,\n",
    "               dcn=None,\n",
    "               plugins=None):\n",
    "    \"\"\"\n",
    "    Builds a U-Net encoder-decoder backbone.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input image channels.\n",
    "        base_channels (int): Base number of feature channels.\n",
    "        num_stages (int): Number of encoder stages.\n",
    "        strides (tuple[int]): Stride of each encoder stage.\n",
    "        enc_num_convs (tuple[int]): Number of convs in each encoder stage.\n",
    "        dec_num_convs (tuple[int]): Number of convs in each decoder stage.\n",
    "        downsamples (tuple[bool]): Whether to downsample with MaxPool per stage.\n",
    "        enc_dilations (tuple[int]): Dilation rates for encoder stages.\n",
    "        dec_dilations (tuple[int]): Dilation rates for decoder stages.\n",
    "        with_cp (bool): Whether to use checkpointing.\n",
    "        conv_cfg (dict): Convolution config.\n",
    "        norm_cfg (dict): Normalization config.\n",
    "        act_cfg (dict): Activation config.\n",
    "        upsample_cfg (dict): Upsample config for decoder.\n",
    "        norm_eval (bool): Whether to freeze norm stats in eval.\n",
    "        dcn (any): Placeholder for deformable convs (not supported).\n",
    "        plugins (any): Placeholder for plugin layers (not supported).\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: A U-Net model with encoder and decoder stages.\n",
    "    \"\"\"\n",
    "    assert dcn is None, 'DCN not implemented'\n",
    "    assert plugins is None, 'Plugins not implemented'\n",
    "    assert len(strides) == num_stages\n",
    "    assert len(enc_num_convs) == num_stages\n",
    "    assert len(dec_num_convs) == (num_stages - 1)\n",
    "    assert len(downsamples) == (num_stages - 1)\n",
    "    assert len(enc_dilations) == num_stages\n",
    "    assert len(dec_dilations) == (num_stages - 1)\n",
    "\n",
    "    encoder = nn.ModuleList()\n",
    "    decoder = nn.ModuleList()\n",
    "    curr_in_channels = in_channels\n",
    "\n",
    "    for i in range(num_stages):\n",
    "        enc_layers = []\n",
    "        if i != 0:\n",
    "            if strides[i] == 1 and downsamples[i - 1]:\n",
    "                enc_layers.append(nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "            upsample = (strides[i] != 1 or downsamples[i - 1])\n",
    "            decoder.append(\n",
    "                build_upconv_block(\n",
    "                    in_channels=base_channels * 2**i,\n",
    "                    skip_channels=base_channels * 2**(i - 1),\n",
    "                    out_channels=base_channels * 2**(i - 1),\n",
    "                    num_convs=dec_num_convs[i - 1],\n",
    "                    stride=1,\n",
    "                    dilation=dec_dilations[i - 1],\n",
    "                    with_cp=with_cp,\n",
    "                    conv_cfg=conv_cfg,\n",
    "                    norm_cfg=norm_cfg,\n",
    "                    act_cfg=act_cfg,\n",
    "                    upsample_cfg=upsample_cfg if upsample else None\n",
    "                )\n",
    "            )\n",
    "\n",
    "        enc_layers.append(\n",
    "            build_basic_conv_block(\n",
    "                in_channels=curr_in_channels,\n",
    "                out_channels=base_channels * 2**i,\n",
    "                num_convs=enc_num_convs[i],\n",
    "                stride=strides[i],\n",
    "                dilation=enc_dilations[i],\n",
    "                with_cp=with_cp,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=act_cfg\n",
    "            )\n",
    "        )\n",
    "        encoder.append(nn.Sequential(*enc_layers))\n",
    "        curr_in_channels = base_channels * 2**i\n",
    "\n",
    "    def forward(x):\n",
    "        \"\"\"\n",
    "        Forward pass of U-Net.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            list[torch.Tensor]: List of outputs at each decoder level.\n",
    "        \"\"\"\n",
    "        enc_outs = []\n",
    "        for enc in encoder:\n",
    "            x = enc(x)\n",
    "            enc_outs.append(x)\n",
    "\n",
    "        dec_outs = [x]\n",
    "        for i in reversed(range(len(decoder))):\n",
    "            x = decoder[i](enc_outs[i], x)\n",
    "            dec_outs.append(x)\n",
    "        return dec_outs\n",
    "\n",
    "    def init_weights(module, pretrained=None):\n",
    "        \"\"\"\n",
    "        Initializes model weights.\n",
    "\n",
    "        Args:\n",
    "            module (nn.Module): The UNet model.\n",
    "            pretrained (str or None): Path to weights or None for random init.\n",
    "        \"\"\"\n",
    "        if isinstance(pretrained, str):\n",
    "            state_dict = torch.load(pretrained, map_location='cpu')\n",
    "            if 'state_dict' in state_dict:\n",
    "                state_dict = state_dict['state_dict']\n",
    "            module.load_state_dict(state_dict, strict=False)\n",
    "        elif pretrained is None:\n",
    "            for m in module.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        else:\n",
    "            raise TypeError('pretrained must be a str or None')\n",
    "\n",
    "    # Package everything into a functional-like module\n",
    "    class UNetWrapper(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "            self.forward = forward.__get__(self, UNetWrapper)\n",
    "\n",
    "        def init_weights(self, pretrained=None):\n",
    "            init_weights(self, pretrained)\n",
    "\n",
    "        def train(self, mode=True):\n",
    "            super().train(mode)\n",
    "            if norm_eval:\n",
    "                for m in self.modules():\n",
    "                    if isinstance(m, nn.BatchNorm2d):\n",
    "                        m.eval()\n",
    "\n",
    "    return UNetWrapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attr_unet(\n",
    "    in_channels=3,\n",
    "    base_channels=64,\n",
    "    num_stages=5,\n",
    "    attr_embedding=128,\n",
    "    strides=(1, 1, 1, 1, 1),\n",
    "    enc_num_convs=(2, 2, 2, 2, 2),\n",
    "    dec_num_convs=(2, 2, 2, 2),\n",
    "    downsamples=(True, True, True, True),\n",
    "    enc_dilations=(1, 1, 1, 1, 1),\n",
    "    dec_dilations=(1, 1, 1, 1),\n",
    "    with_cp=False,\n",
    "    conv_cfg=None,\n",
    "    norm_cfg=dict(type='BN'),\n",
    "    act_cfg=dict(type='ReLU'),\n",
    "    upsample_cfg=dict(type='InterpConv'),\n",
    "    norm_eval=False,\n",
    "    dcn=None,\n",
    "    plugins=None\n",
    "):\n",
    "    assert dcn is None, 'DCN not implemented'\n",
    "    assert plugins is None, 'Plugins not implemented'\n",
    "    assert len(strides) == num_stages\n",
    "    assert len(enc_num_convs) == num_stages\n",
    "    assert len(dec_num_convs) == (num_stages - 1)\n",
    "    assert len(downsamples) == (num_stages - 1)\n",
    "    assert len(enc_dilations) == num_stages\n",
    "    assert len(dec_dilations) == (num_stages - 1)\n",
    "\n",
    "    encoder = nn.ModuleList()\n",
    "    decoder = nn.ModuleList()\n",
    "    curr_in_channels = in_channels + attr_embedding\n",
    "\n",
    "    for i in range(num_stages):\n",
    "        enc_block = []\n",
    "        if i != 0:\n",
    "            if strides[i] == 1 and downsamples[i - 1]:\n",
    "                enc_block.append(nn.MaxPool2d(kernel_size=2))\n",
    "            upsample = (strides[i] != 1 or downsamples[i - 1])\n",
    "            decoder.append(\n",
    "                build_upconv_block(\n",
    "                    in_channels=base_channels * 2**i,\n",
    "                    skip_channels=base_channels * 2**(i - 1),\n",
    "                    out_channels=base_channels * 2**(i - 1),\n",
    "                    num_convs=dec_num_convs[i - 1],\n",
    "                    stride=1,\n",
    "                    dilation=dec_dilations[i - 1],\n",
    "                    with_cp=with_cp,\n",
    "                    conv_cfg=conv_cfg,\n",
    "                    norm_cfg=norm_cfg,\n",
    "                    act_cfg=act_cfg,\n",
    "                    upsample_cfg=upsample_cfg if upsample else None\n",
    "                )\n",
    "            )\n",
    "\n",
    "        enc_block.append(\n",
    "            build_basic_conv_block(\n",
    "                in_channels=curr_in_channels,\n",
    "                out_channels=base_channels * 2**i,\n",
    "                num_convs=enc_num_convs[i],\n",
    "                stride=strides[i],\n",
    "                dilation=enc_dilations[i],\n",
    "                with_cp=with_cp,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=act_cfg\n",
    "            )\n",
    "        )\n",
    "        encoder.append(nn.Sequential(*enc_block))\n",
    "        curr_in_channels = base_channels * 2**i\n",
    "\n",
    "    def forward(x, attr_emb):\n",
    "        \"\"\"\n",
    "        Forward pass of AttrUNet.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input image tensor.\n",
    "            attr_emb (torch.Tensor): Attribute embedding (B, C_attr).\n",
    "\n",
    "        Returns:\n",
    "            list[torch.Tensor]: Decoder outputs (multi-level).\n",
    "        \"\"\"\n",
    "        enc_outs = []\n",
    "        B, C_attr = attr_emb.size()\n",
    "        for enc in encoder:\n",
    "            _, _, H, W = x.shape\n",
    "            attr = attr_emb.view(B, C_attr, 1, 1).expand(-1, -1, H, W)\n",
    "            x = enc(torch.cat([x, attr], dim=1))\n",
    "            enc_outs.append(x)\n",
    "\n",
    "        dec_outs = [x]\n",
    "        for i in reversed(range(len(decoder))):\n",
    "            x = decoder[i](enc_outs[i], x)\n",
    "            dec_outs.append(x)\n",
    "\n",
    "        return dec_outs\n",
    "\n",
    "    def init_weights(module, pretrained=None):\n",
    "        \"\"\"\n",
    "        Initialize weights.\n",
    "\n",
    "        Args:\n",
    "            module (nn.Module): The UNet model.\n",
    "            pretrained (str or None): Optional path to checkpoint.\n",
    "        \"\"\"\n",
    "        if isinstance(pretrained, str):\n",
    "            state_dict = torch.load(pretrained, map_location='cpu')\n",
    "            if 'state_dict' in state_dict:\n",
    "                state_dict = state_dict['state_dict']\n",
    "            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "            module.load_state_dict(state_dict, strict=False)\n",
    "        elif pretrained is None:\n",
    "            for m in module.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        else:\n",
    "            raise TypeError('pretrained must be a str or None')\n",
    "\n",
    "    class AttrUNetWrapper(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "            self.forward = forward.__get__(self, AttrUNetWrapper)\n",
    "\n",
    "        def init_weights(self, pretrained=None):\n",
    "            init_weights(self, pretrained)\n",
    "\n",
    "        def train(self, mode=True):\n",
    "            super().train(mode)\n",
    "            if norm_eval:\n",
    "                for m in self.modules():\n",
    "                    if isinstance(m, nn.BatchNorm2d):\n",
    "                        m.eval()\n",
    "\n",
    "    return AttrUNetWrapper()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orientation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
