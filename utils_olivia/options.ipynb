{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Provides a way of using operating system-dependent functionality like reading or writing to the file system.\n",
    "import os.path as osp  # Provides functions for manipulating file paths in a way that is compatible with the operating system.\n",
    "from collections import OrderedDict  # Provides a dictionary subclass that maintains the order of keys as they are added.\n",
    "\n",
    "import yaml  # Provides functionality to parse and emit YAML, a human-readable data serialization standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: ordered_yaml\n",
    "\n",
    "Purpose:\n",
    "The ordered_yaml function is designed to support the use of OrderedDict when loading and dumping YAML data. This ensures that the order of keys in the YAML file is preserved when it is read into a Python dictionary and when it is written back to a YAML file.\n",
    "\n",
    "Functionality:\n",
    "Imports: Attempts to import the C-based Loader and Dumper for performance. If unavailable, it falls back to the pure Python versions.\n",
    "\n",
    "Custom Representer and Constructor:\n",
    "dict_representer: A custom representer function that tells the YAML dumper how to serialize an OrderedDict by iterating over its items.\n",
    "\n",
    "dict_constructor: A custom constructor function that tells the YAML loader how to deserialize a mapping node into an OrderedDict.\n",
    "Integration with YAML:\n",
    "Registers the custom representer and constructor with the Dumper and Loader, respectively, to handle OrderedDict objects.\n",
    "Returns: The function returns the customized Loader and Dumper that can be used to load and dump YAML data while preserving key order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_yaml():\n",
    "    \"\"\"Support OrderedDict for yaml.\n",
    "\n",
    "    Returns:\n",
    "        yaml Loader and Dumper.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to import the C-based Dumper and Loader for better performance\n",
    "        from yaml import CDumper as Dumper\n",
    "        from yaml import CLoader as Loader\n",
    "    except ImportError:\n",
    "        # Fallback to the pure Python Dumper and Loader if C-based ones are unavailable\n",
    "        from yaml import Dumper, Loader\n",
    "\n",
    "    # Default mapping tag used by YAML\n",
    "    _mapping_tag = yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG\n",
    "\n",
    "    def dict_representer(dumper, data):\n",
    "        # Custom representer to serialize OrderedDict as a regular dictionary\n",
    "        return dumper.represent_dict(data.items())\n",
    "\n",
    "    def dict_constructor(loader, node):\n",
    "        # Custom constructor to deserialize a YAML mapping node into an OrderedDict\n",
    "        return OrderedDict(loader.construct_pairs(node))\n",
    "\n",
    "    # Register the custom representer and constructor with the Dumper and Loader\n",
    "    Dumper.add_representer(OrderedDict, dict_representer)\n",
    "    Loader.add_constructor(_mapping_tag, dict_constructor)\n",
    "\n",
    "    # Return the customized Loader and Dumper\n",
    "    return Loader, Dumper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage\n",
    "Here's how you might use the ordered_yaml function in practice:\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Get the customized Loader and Dumper\n",
    "Loader, Dumper = ordered_yaml()\n",
    "\n",
    "# Load a YAML file while preserving the order of keys\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=Loader)\n",
    "\n",
    "# Dump the OrderedDict back to a YAML file\n",
    "with open('output.yaml', 'w') as f:\n",
    "    yaml.dump(config, f, Dumper=Dumper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function: parse\n",
    "# Purpose: Parse an option file and set up the environment for training or testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: parse\n",
    "# Purpose: Parse an option file and set up the environment for training or testing.\n",
    "\n",
    "def parse(opt_path, is_train=True):\n",
    "    \"\"\"Parse option file.\n",
    "\n",
    "    Args:\n",
    "        opt_path (str): Option file path.\n",
    "        is_train (bool): Indicate whether in training or not. Default: True.\n",
    "\n",
    "    Returns:\n",
    "        dict: Parsed options.\n",
    "    \"\"\"\n",
    "    # Open the option file and load its contents using the ordered YAML loader\n",
    "    with open(opt_path, mode='r') as f:\n",
    "        Loader, _ = ordered_yaml()  # Get the customized YAML Loader\n",
    "        opt = yaml.load(f, Loader=Loader)  # Load the YAML file into a dictionary\n",
    "\n",
    "    # Prepare the GPU list as a comma-separated string\n",
    "    gpu_list = ','.join(str(x) for x in opt['gpu_ids'])\n",
    "    # Set the CUDA_VISIBLE_DEVICES environment variable if specified\n",
    "    if opt.get('set_CUDA_VISIBLE_DEVICES', None):\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = gpu_list\n",
    "        print('export CUDA_VISIBLE_DEVICES=' + gpu_list, flush=True)\n",
    "    else:\n",
    "        print('gpu_list: ', gpu_list, flush=True)\n",
    "\n",
    "    # Set the training mode flag in the options\n",
    "    opt['is_train'] = is_train\n",
    "\n",
    "    # Set up paths for the experiment\n",
    "    opt['path'] = {}\n",
    "    # Determine the root path of the project\n",
    "    opt['path']['root'] = osp.abspath(osp.join(__file__, osp.pardir, osp.pardir))\n",
    "    if is_train:\n",
    "        # Determine the path for experiments based on debug mode\n",
    "        if opt.get('debug_path', None):\n",
    "            experiments_path = 'experiments_debug'\n",
    "        else:\n",
    "            experiments_path = 'experiments'\n",
    "        # Set up paths for models, logs, and visualizations\n",
    "        experiments_root = osp.join(opt['path']['root'], experiments_path, opt['name'])\n",
    "        opt['path']['experiments_root'] = experiments_root\n",
    "        opt['path']['models'] = osp.join(experiments_root, 'models')\n",
    "        opt['path']['log'] = experiments_root\n",
    "        opt['path']['visualization'] = osp.join(experiments_root, 'visualization')\n",
    "\n",
    "        # Adjust options for debug mode\n",
    "        if 'debug' in opt['name']:\n",
    "            opt['debug'] = True\n",
    "            opt['val_freq'] = 1\n",
    "            opt['print_freq'] = 1\n",
    "            opt['save_checkpoint_freq'] = 1\n",
    "    else:  # If not in training mode, set up paths for results\n",
    "        results_root = osp.join(opt['path']['root'], 'results', opt['name'])\n",
    "        opt['path']['results_root'] = results_root\n",
    "        opt['path']['log'] = results_root\n",
    "        opt['path']['visualization'] = osp.join(results_root, 'visualization')\n",
    "\n",
    "    return opt  # Return the parsed options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exmaple usage of parse function\n",
    "# Configuration Parsing \n",
    "Purpose\n",
    "This code is designed to parse a YAML configuration file for our experiment, set up the necessary environment, and organize paths for training or testing. It ensures that the configuration options are loaded into a structured format, allowing for easy access and manipulation of experiment settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export CUDA_VISIBLE_DEVICES=0,1\n",
      "OrderedDict({'name': 'my_experiment', 'gpu_ids': [0, 1], 'set_CUDA_VISIBLE_DEVICES': True, 'debug_path': False, 'is_train': True, 'path': {'root': '/Users/oliviashen/uva/ds6050_deep_learning/final_project_styleswap', 'experiments_root': '/Users/oliviashen/uva/ds6050_deep_learning/final_project_styleswap/experiments/my_experiment', 'models': '/Users/oliviashen/uva/ds6050_deep_learning/final_project_styleswap/experiments/my_experiment/models', 'log': '/Users/oliviashen/uva/ds6050_deep_learning/final_project_styleswap/experiments/my_experiment', 'visualization': '/Users/oliviashen/uva/ds6050_deep_learning/final_project_styleswap/experiments/my_experiment/visualization'}})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Define the ordered_yaml function (as previously discussed)\n",
    "def ordered_yaml():\n",
    "    try:\n",
    "        from yaml import CDumper as Dumper\n",
    "        from yaml import CLoader as Loader\n",
    "    except ImportError:\n",
    "        from yaml import Dumper, Loader\n",
    "\n",
    "    _mapping_tag = yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG\n",
    "\n",
    "    def dict_representer(dumper, data):\n",
    "        return dumper.represent_dict(data.items())\n",
    "\n",
    "    def dict_constructor(loader, node):\n",
    "        return OrderedDict(loader.construct_pairs(node))\n",
    "\n",
    "    Dumper.add_representer(OrderedDict, dict_representer)\n",
    "    Loader.add_constructor(_mapping_tag, dict_constructor)\n",
    "\n",
    "    return Loader, Dumper\n",
    "\n",
    "# Define the parse function (as previously discussed)\n",
    "def parse(opt_path, is_train=True):\n",
    "    with open(opt_path, mode='r') as f:\n",
    "        Loader, _ = ordered_yaml()\n",
    "        opt = yaml.load(f, Loader=Loader)\n",
    "\n",
    "    gpu_list = ','.join(str(x) for x in opt['gpu_ids'])\n",
    "    if opt.get('set_CUDA_VISIBLE_DEVICES', None):\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = gpu_list\n",
    "        print('export CUDA_VISIBLE_DEVICES=' + gpu_list, flush=True)\n",
    "    else:\n",
    "        print('gpu_list: ', gpu_list, flush=True)\n",
    "\n",
    "    opt['is_train'] = is_train\n",
    "\n",
    "    opt['path'] = {}\n",
    "    # Use the current working directory as the root path\n",
    "    opt['path']['root'] = osp.abspath(osp.join(os.getcwd(), osp.pardir, osp.pardir))\n",
    "    if is_train:\n",
    "        if opt.get('debug_path', None):\n",
    "            experiments_path = 'experiments_debug'\n",
    "        else:\n",
    "            experiments_path = 'experiments'\n",
    "        experiments_root = os.path.join(opt['path']['root'], experiments_path, opt['name'])\n",
    "        opt['path']['experiments_root'] = experiments_root\n",
    "        opt['path']['models'] = os.path.join(experiments_root, 'models')\n",
    "        opt['path']['log'] = experiments_root\n",
    "        opt['path']['visualization'] = os.path.join(experiments_root, 'visualization')\n",
    "\n",
    "        if 'debug' in opt['name']:\n",
    "            opt['debug'] = True\n",
    "            opt['val_freq'] = 1\n",
    "            opt['print_freq'] = 1\n",
    "            opt['save_checkpoint_freq'] = 1\n",
    "    else:\n",
    "        results_root = os.path.join(opt['path']['root'], 'results', opt['name'])\n",
    "        opt['path']['results_root'] = results_root\n",
    "        opt['path']['log'] = results_root\n",
    "        opt['path']['visualization'] = os.path.join(results_root, 'visualization')\n",
    "\n",
    "    return opt\n",
    "\n",
    "# Use the parse function to load the configuration\n",
    "options = parse('config.yaml', is_train=True)\n",
    "\n",
    "# Print the parsed options\n",
    "print(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE USAGE\n",
    "# Use the parse function to load the configuration\n",
    "options = parse('config.yaml', is_train=True)\n",
    "\n",
    "# Print the parsed options\n",
    "print(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: dict2str\n",
    "Purpose:\n",
    "The dict2str function is designed to convert a dictionary into a formatted string. This is particularly useful for printing configuration options or other structured data in a readable format, especially when dealing with nested dictionaries.\n",
    "Functionality:\n",
    "Input: The function takes two arguments:\n",
    "opt: The dictionary to be converted into a string.\n",
    "indent_level: An optional integer that specifies the level of indentation for nested dictionaries. The default is 1.\n",
    "Output: It returns a string that represents the dictionary in a structured and indented format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: dict2str\n",
    "# Purpose: Convert a dictionary to a formatted string for easy printing of options.\n",
    "\n",
    "def dict2str(opt, indent_level=1):\n",
    "    \"\"\"Convert a dictionary to a formatted string for printing options.\n",
    "\n",
    "    Args:\n",
    "        opt (dict): The dictionary containing options to be converted.\n",
    "        indent_level (int): The level of indentation for nested dictionaries. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string representation of the dictionary.\n",
    "    \"\"\"\n",
    "    msg = ''  # Initialize an empty string to build the message\n",
    "    for k, v in opt.items():\n",
    "        if isinstance(v, dict):\n",
    "            # If the value is a dictionary, recursively convert it to a string\n",
    "            msg += ' ' * (indent_level * 2) + k + ':[\\n'\n",
    "            msg += dict2str(v, indent_level + 1)\n",
    "            msg += ' ' * (indent_level * 2) + ']\\n'\n",
    "        else:\n",
    "            # Otherwise, add the key-value pair to the message\n",
    "            msg += ' ' * (indent_level * 2) + k + ': ' + str(v) + '\\n'\n",
    "    return msg  # Return the formatted string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a sample configuration dictionary\n",
    "config = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'model': {\n",
    "        'type': 'ResNet',\n",
    "        'layers': 50\n",
    "    },\n",
    "    'optimizer': 'Adam',\n",
    "    'epochs': 100\n",
    "}\n",
    "\n",
    "# Use the dict2str function to convert the dictionary to a formatted string\n",
    "formatted_config = dict2str(config)\n",
    "\n",
    "# Print the formatted configuration\n",
    "print(\"Configuration Options:\\n\", formatted_config)\n",
    "\n",
    "\n",
    "# Configuration Options:\n",
    "   learning_rate: 0.001\n",
    "  batch_size: 32\n",
    "  model:[\n",
    "    type: ResNet\n",
    "    layers: 50\n",
    "  ]\n",
    "  optimizer: Adam\n",
    "  epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Options:\n",
      "   learning_rate: 0.001\n",
      "  batch_size: 32\n",
      "  model:[\n",
      "    type: ResNet\n",
      "    layers: 50\n",
      "  ]\n",
      "  optimizer: Adam\n",
      "  epochs: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Define a sample configuration dictionary\n",
    "# config = {\n",
    "#     'learning_rate': 0.001,\n",
    "#     'batch_size': 32,\n",
    "#     'model': {\n",
    "#         'type': 'ResNet',\n",
    "#         'layers': 50\n",
    "#     },\n",
    "#     'optimizer': 'Adam',\n",
    "#     'epochs': 100\n",
    "# }\n",
    "\n",
    "# # Use the dict2str function to convert the dictionary to a formatted string\n",
    "# formatted_config = dict2str(config)\n",
    "\n",
    "# # Print the formatted configuration\n",
    "# print(\"Configuration Options:\\n\", formatted_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLIVIA: Function: dict_to_nonedict , I THINK WE CAN DELETE THIS FUNCTION\n",
    "\n",
    "When to Keep It\n",
    "Frequent Use: If you often need to convert dictionaries to a form that safely handles missing keys, keeping this function is beneficial.\n",
    "Code Readability: It encapsulates the logic for converting dictionaries, making your code cleaner and more readable.\n",
    "Reusability: If you foresee needing this functionality in multiple parts of your project, it's efficient to have a dedicated function.\n",
    "\n",
    "When to Remove It\n",
    "Unused Functionality: If you find that this function is not being used anywhere in your codebase, it might be unnecessary to keep it.\n",
    "Simplification: If you're trying to simplify your code and reduce the number of functions, removing unused or rarely used functions can help.\n",
    "Alternative Solutions: If you've implemented a different approach to handle missing keys or if your project requirements have changed, this function might no longer be relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLIVIA: Function: dict_to_nonedict\n",
    "# Purpose: Convert a standard dictionary into a NoneDict, which returns None for missing keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: dict_to_nonedict\n",
    "# Purpose: Convert a standard dictionary into a NoneDict, which returns None for missing keys.\n",
    "\n",
    "class NoneDict(dict):\n",
    "    \"\"\"None dict. It will return none if key is not in the dict.\"\"\"\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def dict_to_nonedict(opt):\n",
    "    \"\"\"Convert to NoneDict, which returns None for missing keys.\n",
    "\n",
    "    Args:\n",
    "        opt (dict): Option dict.\n",
    "\n",
    "    Returns:\n",
    "        (dict): NoneDict for options.\n",
    "    \"\"\"\n",
    "    if isinstance(opt, dict):\n",
    "        # Create a new dictionary to store converted items\n",
    "        new_opt = dict()\n",
    "        # Recursively convert each key-value pair\n",
    "        for key, sub_opt in opt.items():\n",
    "            new_opt[key] = dict_to_nonedict(sub_opt)\n",
    "        # Return a NoneDict initialized with the converted dictionary\n",
    "        return NoneDict(**new_opt)\n",
    "    elif isinstance(opt, list):\n",
    "        # If the input is a list, recursively convert each element\n",
    "        return [dict_to_nonedict(sub_opt) for sub_opt in opt]\n",
    "    else:\n",
    "        # Return the item as is if it's neither a dict nor a list\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE USAGE\n",
    "# Define a sample configuration dictionary\n",
    "config = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'model': {\n",
    "        'type': 'ResNet',\n",
    "        'layers': 50\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the configuration dictionary to a NoneDict\n",
    "none_dict_config = dict_to_nonedict(config)\n",
    "\n",
    "# Access existing and non-existing keys\n",
    "print(none_dict_config['learning_rate'])  # Output: 0.001\n",
    "print(none_dict_config['optimizer'])      # Output: None (instead of KeyError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
